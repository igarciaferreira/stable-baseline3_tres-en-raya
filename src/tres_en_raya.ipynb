{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6Dx1HubDBjK"
      },
      "source": [
        "# El juego del tres en raya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJKJbsjdDQ4x"
      },
      "source": [
        "## Instalando dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqjMQD_ZCikZ"
      },
      "outputs": [],
      "source": [
        "!pip install stable-baselines3[extra]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhKZBO88DeFa"
      },
      "source": [
        "## El gimnasio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EP_RJErMDVCl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "from gym import spaces\n",
        "import random\n",
        "\n",
        "\n",
        "class tresEnRaya(gym.Env):\n",
        "\n",
        "  def __init__(self, columns=3, rows=3):\n",
        "    self.columns = columns\n",
        "    self.rows = rows\n",
        "    self.tablero = np.zeros(9, np.uint8)\n",
        "    self.done = False\n",
        "    self.turno = 0\n",
        "\n",
        "    # Definimos el n√∫mero de acciones que queremos realizar\n",
        "    self.action_space = spaces.Discrete(9)\n",
        "\n",
        "    # Vamos a definir el entorno\n",
        "    self.observation_space = spaces.Box(\n",
        "        low=0, \n",
        "        high=2,\n",
        "        shape=(9,), \n",
        "        dtype=np.uint8)\n",
        "    \n",
        "\n",
        "  def __turno_aleatorio(self):\n",
        "    colocada = 0\n",
        "    while colocada == 0:\n",
        "      alea = random.randint(0, 8)\n",
        "      if self.tablero[alea] == 0:\n",
        "        self.tablero[alea] = 2\n",
        "        colocada = 1\n",
        "    return self.tablero\n",
        "\n",
        "  def __comprobar_ganador(self):\n",
        "    # Comprobamos si gana la IA ha ganado\n",
        "    # Horizontales\n",
        "    if self.tablero[0] == 1 and self.tablero[1] == 1 and self.tablero[2] == 1:\n",
        "      self.done = True\n",
        "      return 1\n",
        "    if self.tablero[3] == 1 and self.tablero[4] == 1 and self.tablero[5] == 1:\n",
        "      self.done = True\n",
        "      return 1\n",
        "    if self.tablero[6] == 1 and self.tablero[7] == 1 and self.tablero[8] == 1:\n",
        "      self.done = True\n",
        "      return 1\n",
        "    # Verticales\n",
        "    if self.tablero[0] == 1 and self.tablero[3] == 1 and self.tablero[6] == 1:\n",
        "      self.done = True\n",
        "      return 1\n",
        "    if self.tablero[1] == 1 and self.tablero[4] == 1 and self.tablero[7] == 1:\n",
        "      self.done = True\n",
        "      return 1\n",
        "    if self.tablero[2] == 1 and self.tablero[5] == 1 and self.tablero[8] == 1:\n",
        "      self.done = True\n",
        "      return 1\n",
        "    # Diagonales\n",
        "    if self.tablero[0] == 1 and self.tablero[4] == 1 and self.tablero[8] == 1:\n",
        "      self.done = True\n",
        "      return 1\n",
        "    if self.tablero[2] == 1 and self.tablero[4] == 1 and self.tablero[6] == 1:\n",
        "      self.done = True\n",
        "      return 1\n",
        "\n",
        "    # Comprobamos si ha ganado el aleatorio\n",
        "    # Horizontales\n",
        "    if self.tablero[0] == 2 and self.tablero[1] == 2 and self.tablero[2] == 2:\n",
        "      self.done = True\n",
        "      return -1\n",
        "    if self.tablero[3] == 2 and self.tablero[4] == 2 and self.tablero[5] == 2:\n",
        "      self.done = True\n",
        "      return -1\n",
        "    if self.tablero[6] == 2 and self.tablero[7] == 2 and self.tablero[8] == 2:\n",
        "      self.done = True\n",
        "      return -1\n",
        "    # Verticales\n",
        "    if self.tablero[0] == 2 and self.tablero[3] == 2 and self.tablero[6] == 2:\n",
        "      self.done = True\n",
        "      return -1\n",
        "    if self.tablero[1] == 2 and self.tablero[4] == 2 and self.tablero[7] == 2:\n",
        "      self.done = True\n",
        "      return -1\n",
        "    if self.tablero[2] == 2 and self.tablero[5] == 2 and self.tablero[8] == 2:\n",
        "      self.done = True\n",
        "      return -1\n",
        "    # Diagonales\n",
        "    if self.tablero[0] == 2 and self.tablero[4] == 2 and self.tablero[8] == 2:\n",
        "      self.done = True\n",
        "      return -1\n",
        "    if self.tablero[2] == 2 and self.tablero[4] == 2 and self.tablero[6] == 2:\n",
        "      self.done = True\n",
        "      return -1\n",
        "    return 0.5\n",
        "    \n",
        "  def reset(self):\n",
        "    \"\"\"\n",
        "    Importante: the observation must be a numpy array\n",
        "    :return: (np.array) \n",
        "    \"\"\"\n",
        "    self.tablero = np.zeros(9, np.uint8)\n",
        "    observation = np.zeros(9, np.uint8)\n",
        "    self.turno = 0\n",
        "    self.done = False\n",
        "    return observation \n",
        "    \n",
        "  def step(self, action):\n",
        "    if self.tablero[action] != 0:\n",
        "      observation = self.tablero\n",
        "      self.done = True\n",
        "      reward = -1\n",
        "      info = {\"Error\": \"Intento hacer trampa\"}\n",
        "      return observation, reward, self.done, info\n",
        "    self.tablero[action] = 1\n",
        "    self.turno += 1\n",
        "    observation = self.tablero\n",
        "    reward = self.__comprobar_ganador()\n",
        "    if self.turno == 5:\n",
        "      self.done = True\n",
        "    info = {}\n",
        "    if self.done == False:\n",
        "      self.tablero = self.__turno_aleatorio()\n",
        "      observation = self.tablero\n",
        "    return observation, reward, self.done, info\n",
        " \n",
        "  def render(self, mode='human'):\n",
        "    print(\"\")\n",
        "    print(\"turno: \" + str(self.turno))\n",
        "    for i in range(9):\n",
        "      if self.tablero[i]==0:\n",
        "        print(\"   |\", end=\"\")\n",
        "      elif self.tablero[i]==1:\n",
        "        print(\" O |\",end=\"\")\n",
        "      elif self.tablero[i]==2:\n",
        "        print(\" X |\",end=\"\")\n",
        "      if (i+1) % 3 == 0:\n",
        "        print(\"\")\n",
        "    print(\"\")\n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afVJn8xmJNYc"
      },
      "source": [
        "# Validamos el entorno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XucuiuNJMxo"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.env_checker import check_env\n",
        "env = tresEnRaya()\n",
        "check_env(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNTy8t7E1fGu"
      },
      "source": [
        "## Probar el entorno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DI5xVN35JRSs"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.ppo.policies import MlpPolicy\n",
        "\n",
        "env = tresEnRaya()\n",
        "model = PPO(MlpPolicy, env, verbose=0).learn(int(50000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAcPPSkZB6fm"
      },
      "outputs": [],
      "source": [
        "model.save(\"PPO5millonesFinal\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zq1LAq4DBk6X"
      },
      "outputs": [],
      "source": [
        "env = tresEnRaya()\n",
        "recompensas_finales = []\n",
        "num_episodes = 5\n",
        "for i in range(num_episodes):\n",
        "  recompensas_episodio = []\n",
        "  done = False\n",
        "  obs = env.reset()\n",
        "  while not done:\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, reward, done, info = env.step(action)\n",
        "    # env.render()\n",
        "    recompensas_episodio.append(reward)\n",
        "  env.render()\n",
        "  print(info)\n",
        "  recompensas_finales.append(sum(recompensas_episodio))\n",
        "  # print(\"Fin\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "6 - tres en raya.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
